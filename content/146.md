# LRU缓存
## 概念解释
LRU缓存（Least Recently Used Cache）是一种常见的缓存淘汰策略，它的核心思想是：当缓存空间不足时，优先淘汰那些最近最少被使用的缓存项。
在计算机科学中，缓存是一种存储技术，用于临时保存经常访问的数据，以便快速访问。由于缓存的空间通常有限，当缓存满了之后，就需要决定哪些数据应该被淘汰，以便为新的数据腾出空间。LRU缓存就是基于“最近最少使用”的原则来决定哪些数据应该被淘汰。
具体来说，当以下情况发生时，LRU缓存会工作：
1. **缓存命中（Cache Hit）**：当请求的数据在缓存中时，称为缓存命中。这时，数据会被返回，并且这个数据项会被标记为最近被使用过的，因为它刚刚被访问了。
2. **缓存未命中（Cache Miss）**：当请求的数据不在缓存中时，称为缓存未命中。这时，数据需要从其他数据源（如数据库或磁盘）加载到缓存中。如果缓存已满，则需要根据LRU策略淘汰一个数据项。
3. **更新缓存**：当缓存中的数据被修改时，相应的缓存项也需要被更新，以反映最新的数据状态。
LRU缓存的实现通常需要满足以下两个条件：
- **快速访问**：需要能够快速判断一个数据项是否在缓存中，这通常通过哈希表来实现。
- **快速更新**：需要能够快速地将最近被访问的数据项移动到缓存列表的前端，这通常通过双向链表来实现。
在实际应用中，LRU缓存可以有效地提高系统的性能，减少对慢速存储介质的访问次数，从而加快数据的读取速度。

## 问题
请你设计并实现一个满足  LRU (最近最少使用) 缓存 约束的数据结构。
实现 LRUCache 类：
- LRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存
- int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。
- void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。
- 函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。



示例：
```
输入
["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"]
[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]
输出
[null, null, null, 1, null, -1, null, -1, 3, 4]

解释
LRUCache lRUCache = new LRUCache(2);
lRUCache.put(1, 1); // 缓存是 {1=1}
lRUCache.put(2, 2); // 缓存是 {1=1, 2=2}
lRUCache.get(1);    // 返回 1
lRUCache.put(3, 3); // 该操作会使得关键字 2 作废，缓存是 {1=1, 3=3}
lRUCache.get(2);    // 返回 -1 (未找到)
lRUCache.put(4, 4); // 该操作会使得关键字 1 作废，缓存是 {4=4, 3=3}
lRUCache.get(1);    // 返回 -1 (未找到)
lRUCache.get(3);    // 返回 3
lRUCache.get(4);    // 返回 4
```
对示例进一步解释LRU缓存的工作过程：
1. **初始化缓存**:
   - `LRUCache lRUCache = new LRUCache(2);`
   - 这行代码初始化了一个容量为2的LRU缓存。
2. **添加缓存项**:
   - `lRUCache.put(1, 1);` 
   - 缓存目前为 `{1=1}`。这是缓存中的第一个项。
3. **添加另一个缓存项**:
   - `lRUCache.put(2, 2);`
   - 缓存目前为 `{1=1, 2=2}`。现在缓存已满。
4. **获取缓存项**:
   - `lRUCache.get(1);`
   - 返回 `1`。缓存 `{1=1, 2=2}` 不变，因为1是最近访问的，所以它移动到了缓存的头部。
5. **添加新的缓存项，导致缓存满，需要淘汰一个项**:
   - `lRUCache.put(3, 3);`
   - 缓存目前为 `{1=1, 3=3}`。由于缓存容量为2，添加3时，最久未使用的2被淘汰。
6. **尝试获取已被淘汰的缓存项**:
   - `lRUCache.get(2);`
   - 返回 `-1`。因为2已经被淘汰，不在缓存中。
7. **添加新的缓存项，再次导致缓存满，需要淘汰一个项**:
   - `lRUCache.put(4, 4);`
   - 缓存目前为 `{3=3, 4=4}`。由于缓存容量为2，添加4时，最久未使用的1被淘汰。
8. **尝试获取已被淘汰的缓存项**:
   - `lRUCache.get(1);`
   - 返回 `-1`。因为1已经被淘汰，不在缓存中。
9. **获取缓存项**:
   - `lRUCache.get(3);`
   - 返回 `3`。缓存 `{3=3, 4=4}` 不变，因为3是最近访问的。
10. **获取缓存项**:
    - `lRUCache.get(4);`
    - 返回 `4`。缓存 `{3=3, 4=4}` 不变，因为4是最近访问的。
在整个过程中，LRU缓存确保了最近被访问的项不会被淘汰，而最久未使用的项在缓存达到容量上限时会被淘汰。通过这种方式，LRU缓存适用于那些访问模式具有局部性的场景，即最近被访问的数据在未来一段时间内很可能再次被访问。

## 解答
要实现一个满足 LRU (最近最少使用) 缓存约束的数据结构，我们需要在 O(1) 时间复杂度内完成 `get` 和 `put` 操作。为了达到这个要求，我们可以使用哈希表（字典）来快速访问节点，同时使用双向链表来维护节点的顺序，从而在 O(1) 时间复杂度内完成对最近最少使用节点的删除和添加操作。
下面是一个 Python 代码示例，实现了 LRUCache 类：
```python
class Node:
    def __init__(self, key, value):
        self.key = key
        self.value = value
        self.prev = None
        self.next = None
class LRUCache:
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = {}  # 哈希表，用于快速访问节点
        self.head = Node(0, 0)  # 双向链表的头节点
        self.tail = Node(0, 0)  # 双向链表的尾节点
        self.head.next = self.tail
        self.tail.prev = self.head
    def _remove_node(self, node):
        """移除一个节点"""
        node.prev.next = node.next
        node.next.prev = node.prev
    def _add_node_to_head(self, node):
        """将一个节点添加到头部"""
        node.next = self.head.next
        node.prev = self.head
        self.head.next.prev = node
        self.head.next = node
    def _move_to_head(self, node):
        """将一个节点移动到头部"""
        self._remove_node(node)
        self._add_node_to_head(node)
    def _pop_tail(self):
        """移除尾部节点，即最近最少使用的节点"""
        res = self.tail.prev
        self._remove_node(res)
        return res
    def get(self, key: int) -> int:
        node = self.cache.get(key, None)
        if not node:
            return -1
        # 如果 key 存在，先通过哈希表定位，再移到头部
        self._move_to_head(node)
        return node.value
    def put(self, key: int, value: int) -> None:
        node = self.cache.get(key)
        if not node:
            # 如果 key 不存在，创建一个新的节点
            newNode = Node(key, value)
            self.cache[key] = newNode
            self._add_node_to_head(newNode)
            if len(self.cache) > self.capacity:
                # 如果超出容量，删除尾部节点
                tail = self._pop_tail()
                del self.cache[tail.key]
        else:
            # 如果 key 存在，先更新 value，然后移到头部
            node.value = value
            self._move_to_head(node)
# 测试代码
lRUCache = LRUCache(2)
lRUCache.put(1, 1)
lRUCache.put(2, 2)
print(lRUCache.get(1))  # 返回 1
lRUCache.put(3, 3)
print(lRUCache.get(2))  # 返回 -1 (未找到)
lRUCache.put(4, 4)
print(lRUCache.get(1))  # 返回 -1 (未找到)
print(lRUCache.get(3))  # 返回 3
print(lRUCache.get(4))  # 返回 4
```
这个代码示例实现了 LRUCache 类，包含初始化方法、`get` 方法和 `put` 方法。我们使用了一个双向链表和哈希表来维护缓存，确保了 `get` 和 `put` 方法的时间复杂度为 O(1)。

